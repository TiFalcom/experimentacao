{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "project_dir = Path('__main__').resolve().parents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataSet(Dataset):\n",
    "    def __init__(self, features_file, target_file, mapping_file):\n",
    "        self.features_table = pd.read_parquet(os.path.join(project_dir, 'data', 'interim', features_file))\n",
    "        # TODO: Tirar isso daqui\n",
    "        self.features_table['ano_mes_cruzamento'] = pd.to_datetime(self.features_table['ano_mes_cruzamento'], format='%Y-%m')\n",
    "\n",
    "        self.target_table = pd.read_parquet(os.path.join(project_dir, 'data', 'interim', target_file))\n",
    "        self.mapping = json.load(open(os.path.join(project_dir, 'data', 'interim', mapping_file), 'r'), \n",
    "                                    object_hook=lambda x: {int(k) : v for k,v in x.items()})\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_table.shape[0]\n",
    "\n",
    "\n",
    "    def _get_data(self, idx):\n",
    "        df = self.target_table.iloc[idx : idx+1].reset_index(drop=True)\n",
    "\n",
    "        cc_num = df['cc_num'][0]\n",
    "        ano_mes_sup = pd.to_datetime(df['ano_mes'][0])\n",
    "        ano_mes_inf = pd.to_datetime(df['ano_mes'][0]) - timedelta(days=366)\n",
    "        range_dates = pd.date_range(ano_mes_inf, ano_mes_sup, inclusive='left', freq='MS')\n",
    "\n",
    "        df_default = pd.DataFrame({\n",
    "            'cc_num' : [cc_num] * 12,\n",
    "            'ano_mes_cruzamento' : range_dates\n",
    "        })\n",
    "\n",
    "        df = df.merge(df_default, how='left', on='cc_num')\n",
    "\n",
    "        df_features = self.features_table.iloc[min(self.mapping[cc_num]): max(self.mapping[cc_num])]\n",
    "        \n",
    "        df = df.merge(df_features, how='left', on=['cc_num', 'ano_mes_cruzamento']).fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        df = self._get_data(idx)\n",
    "        return df.drop(columns=['ano_mes', 'ano_mes_cruzamento', 'is_fraud', 'cc_num']), df['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = LSTMDataSet(features_file='features.parquet.gzip', target_file='abt_train.parquet.gzip', mapping_file='dict_cpf_noup.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 ms, sys: 334 Âµs, total: 32.2 ms\n",
      "Wall time: 28.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    count_cpf  sum_cpf  max_cpf  min_cpf   p99_cpf  p90_cpf  p75_cpf  \\\n",
       " 0         0.0     0.00     0.00     0.00    0.0000    0.000   0.0000   \n",
       " 1         0.0     0.00     0.00     0.00    0.0000    0.000   0.0000   \n",
       " 2        56.0  2410.54   204.15     1.84  202.2910  104.935  64.4900   \n",
       " 3        59.0  2861.48   224.75     1.24  210.8764  118.436  74.6100   \n",
       " 4        86.0  6672.74   852.81     1.07  833.4725  133.555  82.4025   \n",
       " 5       102.0  6430.91   698.09     1.16  470.5620  117.461  73.3950   \n",
       " 6        81.0  3543.45   225.48     1.22  223.9360  112.830  63.2600   \n",
       " 7       109.0  8993.78  3075.09     1.02  196.1304  121.272  83.5800   \n",
       " 8       102.0  6355.26  1212.58     1.12  395.3417  103.914  74.4250   \n",
       " 9       100.0  4604.33   152.83     1.12  151.3846  110.343  74.5575   \n",
       " 10       86.0  4585.79   458.09     1.27  262.7600  113.055  68.0325   \n",
       " 11       79.0  3164.89   218.93     1.06  217.6742  104.296  62.9850   \n",
       " \n",
       "     median_cpf  p25_cpf  p10_cpf  ...  sum_mcc_top3 max_mcc_top3 min_mcc_top3  \\\n",
       " 0        0.000   0.0000    0.000  ...          0.00         0.00         0.00   \n",
       " 1        0.000   0.0000    0.000  ...          0.00         0.00         0.00   \n",
       " 2       21.685   6.9375    3.470  ...        356.31        82.08        42.70   \n",
       " 3       29.220  10.0500    4.592  ...        514.19       200.83        12.39   \n",
       " 4       48.865  10.1000    4.255  ...        598.53       261.79         1.07   \n",
       " 5       43.280   8.9100    4.517  ...        540.75       163.17         4.21   \n",
       " 6       34.230   6.1000    3.930  ...        233.78       129.06         3.35   \n",
       " 7       54.050   9.5200    5.390  ...       3412.70      3075.09         1.02   \n",
       " 8       42.885   8.4300    3.829  ...        625.59       132.59         2.25   \n",
       " 9       38.175   7.7325    3.065  ...         64.44         8.98         2.24   \n",
       " 10      39.885   9.9775    4.310  ...        695.45       228.29         9.75   \n",
       " 11      15.770   5.7250    1.926  ...        320.55       218.93         1.22   \n",
       " \n",
       "    p99_mcc_top3  p90_mcc_top3  p75_mcc_top3  median_mcc_top3  p25_mcc_top3  \\\n",
       " 0        0.0000         0.000        0.0000            0.000        0.0000   \n",
       " 1        0.0000         0.000        0.0000            0.000        0.0000   \n",
       " 2       81.2275        73.555       64.8500           58.625       50.1725   \n",
       " 3      198.6955       179.485      140.3650           65.145       20.2175   \n",
       " 4      251.0107       153.997       89.9800           53.735       22.8300   \n",
       " 5      158.5996       117.466      104.6900           48.060       13.5300   \n",
       " 6      123.6114        74.574       33.0800           14.180       10.5150   \n",
       " 7     2753.3510       144.927       69.6675            5.830        2.8825   \n",
       " 8      130.5308       112.926       98.7150           31.980       19.1550   \n",
       " 9        8.9294         8.492        7.9175            4.500        3.4025   \n",
       " 10     218.2300       127.690       87.7850           30.620       15.0000   \n",
       " 11     207.7764       107.394        8.3800            2.470        1.5200   \n",
       " \n",
       "     p10_mcc_top3  p01_mcc_top3  \n",
       " 0          0.000        0.0000  \n",
       " 1          0.000        0.0000  \n",
       " 2         45.975       43.0275  \n",
       " 3         12.465       12.3975  \n",
       " 4          6.537        1.6167  \n",
       " 5          4.410        4.2300  \n",
       " 6          6.476        3.6626  \n",
       " 7          1.420        1.0464  \n",
       " 8          3.996        2.3985  \n",
       " 9          2.507        2.2631  \n",
       " 10        10.660        9.8410  \n",
       " 11         1.452        1.2432  \n",
       " \n",
       " [12 rows x 47 columns],\n",
       " 0     0\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 11    0\n",
       " Name: is_fraud, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "training_data.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
